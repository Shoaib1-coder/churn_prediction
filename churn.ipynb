{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('churn.csv')\n",
    "df.head()\n",
    "df = df.dropna()\n",
    "# Convert Last Interaction to days since\n",
    "df['Last Interaction'] = pd.to_datetime(df['Last Interaction'])\n",
    "df['Days Since Last Interaction'] = (pd.to_datetime(\"today\") - df['Last Interaction']).dt.days\n",
    "df.drop(columns=['Last Interaction','CustomerID'], inplace=True)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Encode categorical columns\n",
    "le = LabelEncoder()\n",
    "df['Gender'] = le.fit_transform(df['Gender'])\n",
    "df['Subscription Type'] = le.fit_transform(df['Subscription Type'])\n",
    "df['Contract Length'] = le.fit_transform(df['Contract Length'])\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# Feature/Target split\n",
    "X = df.drop(\"Churn\", axis=1)\n",
    "y = df[\"Churn\"]\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# train using xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "from xgboost import XGBClassifier\n",
    "model= XGBClassifier( eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "X_pred=model.predict(X_test)\n",
    "print(confusion_matrix(y_test, X_pred))\n",
    "print(classification_report(y_test, X_pred))\n",
    "print(accuracy_score(y_test, X_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Usage Frequency</th>\n",
       "      <th>Support Calls</th>\n",
       "      <th>Payment Delay</th>\n",
       "      <th>Subscription Type</th>\n",
       "      <th>Contract Length</th>\n",
       "      <th>Total Spend</th>\n",
       "      <th>Last Interaction</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>598.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>584.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Annual</td>\n",
       "      <td>757.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Quarterly</td>\n",
       "      <td>232.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Annual</td>\n",
       "      <td>533.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID   Age  Gender  Tenure  Usage Frequency  Support Calls  \\\n",
       "0         1.0  22.0  Female    25.0             14.0            4.0   \n",
       "1         2.0  41.0  Female    28.0             28.0            7.0   \n",
       "2         3.0  47.0    Male    27.0             10.0            2.0   \n",
       "3         4.0  35.0    Male     9.0             12.0            5.0   \n",
       "4         5.0  53.0  Female    58.0             24.0            9.0   \n",
       "\n",
       "   Payment Delay Subscription Type Contract Length  Total Spend  \\\n",
       "0           27.0             Basic         Monthly        598.0   \n",
       "1           13.0          Standard         Monthly        584.0   \n",
       "2           29.0           Premium          Annual        757.0   \n",
       "3           17.0           Premium       Quarterly        232.0   \n",
       "4            2.0          Standard          Annual        533.0   \n",
       "\n",
       "   Last Interaction  Churn  \n",
       "0               9.0    1.0  \n",
       "1              20.0    0.0  \n",
       "2              21.0    0.0  \n",
       "3              18.0    0.0  \n",
       "4              18.0    0.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('churn.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Monthly', 'Annual', 'Quarterly', nan], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Contract Length'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "# Convert Last Interaction to days since\n",
    "df['Last Interaction'] = pd.to_datetime(df['Last Interaction'])\n",
    "df['Days Since Last Interaction'] = (pd.to_datetime(\"today\") - df['Last Interaction']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Last Interaction','CustomerID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Encode categorical columns\n",
    "le = LabelEncoder()\n",
    "df['Gender'] = le.fit_transform(df['Gender'])\n",
    "df['Subscription Type'] = le.fit_transform(df['Subscription Type'])\n",
    "df['Contract Length'] = le.fit_transform(df['Contract Length'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# Feature/Target split\n",
    "X = df.drop(\"Churn\", axis=1)\n",
    "y = df[\"Churn\"]\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38828  6258]\n",
      " [ 1021 54935]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.86      0.91     45086\n",
      "         1.0       0.90      0.98      0.94     55956\n",
      "\n",
      "    accuracy                           0.93    101042\n",
      "   macro avg       0.94      0.92      0.93    101042\n",
      "weighted avg       0.93      0.93      0.93    101042\n",
      "\n",
      "0.9279606500267216\n"
     ]
    }
   ],
   "source": [
    "# train using xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "from xgboost import XGBClassifier\n",
    "model= XGBClassifier( eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "X_pred=model.predict(X_test)\n",
    "print(confusion_matrix(y_test, X_pred))\n",
    "print(classification_report(y_test, X_pred))\n",
    "print(accuracy_score(y_test, X_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgboost.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model,'xgboost.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[38828  6258]\n",
      " [ 1021 54935]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.86      0.91     45086\n",
      "         1.0       0.90      0.98      0.94     55956\n",
      "\n",
      "    accuracy                           0.93    101042\n",
      "   macro avg       0.94      0.92      0.93    101042\n",
      "weighted avg       0.93      0.93      0.93    101042\n",
      "\n",
      "Accuracy Score: 0.9279606500267216\n",
      "\n",
      "âœ… Model and Scaler saved successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"churn.csv\")\n",
    "df = df.dropna()\n",
    "\n",
    "# Feature engineering\n",
    "df['Last Interaction'] = pd.to_datetime(df['Last Interaction'])\n",
    "df['Days Since Last Interaction'] = (pd.to_datetime(\"today\") - df['Last Interaction']).dt.days\n",
    "df.drop(columns=[\"Last Interaction\", \"CustomerID\"], inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "for col in ['Gender', 'Subscription Type', 'Contract Length']:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(\"Churn\", axis=1)\n",
    "y = df[\"Churn\"]\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = XGBClassifier(eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "preds = model.predict(X_test)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, preds))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, preds))\n",
    "\n",
    "model.save_model(\"xgb_churn_model.json\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "print(\"\\nâœ… Model and Scaler saved successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[38986  6100]\n",
      " [ 1894 54062]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.86      0.91     45086\n",
      "         1.0       0.90      0.97      0.93     55956\n",
      "\n",
      "    accuracy                           0.92    101042\n",
      "   macro avg       0.93      0.92      0.92    101042\n",
      "weighted avg       0.92      0.92      0.92    101042\n",
      "\n",
      "Accuracy: 0.9208843847113082\n",
      "Precision: 0.8986070941790499\n",
      "Recall: 0.9661519765530059\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Predict probabilities instead of labels\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # probability for class 1 (churn)\n",
    "\n",
    "# Set a new threshold\n",
    "threshold = 0.7\n",
    "y_pred_thresholded = (y_proba >= threshold).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "cm = confusion_matrix(y_test, y_pred_thresholded)\n",
    "report = classification_report(y_test, y_pred_thresholded)\n",
    "accuracy = accuracy_score(y_test, y_pred_thresholded)\n",
    "precision = precision_score(y_test, y_pred_thresholded)\n",
    "recall = recall_score(y_test, y_pred_thresholded)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold for F1: 0.285621\n",
      "Best F1 Score: 0.9391753191996798\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "best_threshold = thresholds[f1_scores.argmax()]\n",
    "best_f1 = f1_scores.max()\n",
    "\n",
    "print(\"Best Threshold for F1:\", best_threshold)\n",
    "print(\"Best F1 Score:\", best_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[38770  6316]\n",
      " [  825 55131]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.86      0.92     45086\n",
      "         1.0       0.90      0.99      0.94     55956\n",
      "\n",
      "    accuracy                           0.93    101042\n",
      "   macro avg       0.94      0.92      0.93    101042\n",
      "weighted avg       0.93      0.93      0.93    101042\n",
      "\n",
      "Accuracy: 0.9293264187169692\n"
     ]
    }
   ],
   "source": [
    "# Apply the best threshold\n",
    "optimal_threshold = 0.285621\n",
    "y_pred_optimal = (y_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "# Confusion Matrix and Report\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_optimal))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_optimal))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_optimal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\m\\anaconda3\\envs\\streamlit\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "scaled = scaler.transform([[30, 0, 24, 5.0, 0, 0.0, 2, 2, 2400.0, 2]])\n",
    "prediction = model.predict(scaled)\n",
    "print(\"Prediction:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load scaler and model\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "model = XGBClassifier()\n",
    "model.load_model(\"xgb_churn_model.json\")\n",
    "\n",
    "# Define feature names (same order as training)\n",
    "columns = [\n",
    "    \"Age\", \"Gender\", \"Tenure\", \"Usage Frequency\", \"Support Calls\",\n",
    "    \"Payment Delay\", \"Subscription Type\", \"Contract Length\",\n",
    "    \"Total Spend\", \"Days Since Last Interaction\"\n",
    "]\n",
    "\n",
    "# Create input as DataFrame\n",
    "input_data = pd.DataFrame([[\n",
    "    30, 0, 24, 5.0, 0, 0.0, 2, 2, 2400.0, 2\n",
    "]], columns=columns)\n",
    "\n",
    "# Scale and predict\n",
    "scaled_input = scaler.transform(input_data)\n",
    "prediction = model.predict(scaled_input)\n",
    "\n",
    "print(\"Prediction:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn Probability: 0.05196655\n",
      "Prediction (1 = Churn, 0 = No Churn): 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load scaler, model, and threshold\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "best_threshold = joblib.load(\"best_threshold.pkl\")\n",
    "\n",
    "# Load model\n",
    "model = XGBClassifier()\n",
    "model.load_model(\"xgb_churn_model.json\")\n",
    "\n",
    "# Define feature names in training order\n",
    "columns = [\n",
    "    \"Age\", \"Gender\", \"Tenure\", \"Usage Frequency\", \"Support Calls\",\n",
    "    \"Payment Delay\", \"Subscription Type\", \"Contract Length\",\n",
    "    \"Total Spend\", \"Days Since Last Interaction\"\n",
    "]\n",
    "\n",
    "# Example customer input\n",
    "input_data = pd.DataFrame([[  \n",
    "    45,   # Age  \n",
    "    0,    # Gender (1 = Male/Female depending on encoding)  \n",
    "    24,   # Tenure  \n",
    "    5.0,  # Usage Frequency  \n",
    "    0,    # Support Calls  \n",
    "    0.0,  # Payment Delay  \n",
    "    1,    # Subscription Type  \n",
    "    2,    # Contract Length  \n",
    "    2400.0, # Total Spend  \n",
    "    2     # Days Since Last Interaction  \n",
    "]], columns=columns)\n",
    "\n",
    "# Scale input\n",
    "scaled_input = scaler.transform(input_data)\n",
    "\n",
    "# Predict probability of churn\n",
    "proba = model.predict_proba(scaled_input)[:, 1]\n",
    "\n",
    "# Apply custom threshold\n",
    "prediction = (proba >= best_threshold).astype(int)\n",
    "\n",
    "# Output\n",
    "print(\"Churn Probability:\", proba[0])\n",
    "print(\"Prediction (1 = Churn, 0 = No Churn):\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn probability: 0.8331093\n",
      "Churn\n"
     ]
    }
   ],
   "source": [
    "proba = model.predict_proba(scaled_input)[0][1]\n",
    "print(\"Churn probability:\", proba)\n",
    "\n",
    "if proba > 0.6:  # Raise threshold\n",
    "    print(\"Churn\")\n",
    "else:\n",
    "    print(\"Not Churn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn Risk Level: Medium Risk\n"
     ]
    }
   ],
   "source": [
    "def get_churn_risk(prob, threshold=0.1808):\n",
    "    if prob < threshold:\n",
    "        return \"Low Risk\"\n",
    "    elif prob < 0.4:\n",
    "        return \"Medium Risk\"\n",
    "    elif prob < 0.7:\n",
    "        return \"High Risk\"\n",
    "    else:\n",
    "        return \"Very High Risk\"\n",
    "\n",
    "risk_label = get_churn_risk(proba[0])\n",
    "print(\"Churn Risk Level:\", risk_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn Probability: 0.2831\n",
      "Prediction (1 = Churn, 0 = No Churn): 1\n",
      "Churn Risk Level: Medium Risk\n"
     ]
    }
   ],
   "source": [
    "def get_churn_risk(prob, threshold=0.1808):\n",
    "    if prob < threshold:\n",
    "        return \"Low Risk\"\n",
    "    elif prob < 0.4:\n",
    "        return \"Medium Risk\"\n",
    "    elif prob < 0.7:\n",
    "        return \"High Risk\"\n",
    "    else:\n",
    "        return \"Very High Risk\"\n",
    "\n",
    "risk_label = get_churn_risk(proba[0])\n",
    "\n",
    "print(\"Churn Probability:\", round(proba[0], 4))\n",
    "print(\"Prediction (1 = Churn, 0 = No Churn):\", prediction[0])\n",
    "print(\"Churn Risk Level:\", risk_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Best Threshold for F1: 0.1808\n",
      "\n",
      "Confusion Matrix:\n",
      " [[38472  6471]\n",
      " [  768 55331]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.86      0.91     44943\n",
      "         1.0       0.90      0.99      0.94     56099\n",
      "\n",
      "    accuracy                           0.93    101042\n",
      "   macro avg       0.94      0.92      0.93    101042\n",
      "weighted avg       0.93      0.93      0.93    101042\n",
      "\n",
      "Accuracy Score: 0.928356525009402\n",
      "Precision: 0.8952946506585547\n",
      "Recall: 0.9863099163977967\n",
      "\n",
      "âœ… Model, Scaler, and Best Threshold saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, precision_recall_curve\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load and clean data\n",
    "df = pd.read_csv(\"churn.csv\")\n",
    "df = df.dropna()\n",
    "\n",
    "# Feature engineering\n",
    "df['Last Interaction'] = pd.to_datetime(df['Last Interaction'])\n",
    "df['Days Since Last Interaction'] = (pd.to_datetime(\"today\") - df['Last Interaction']).dt.days\n",
    "df.drop(columns=[\"Last Interaction\", \"CustomerID\"], inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "for col in ['Gender', 'Subscription Type', 'Contract Length']:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(\"Churn\", axis=1)\n",
    "y = df[\"Churn\"]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train model\n",
    "model = XGBClassifier(eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Threshold tuning using F1\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "print(f\"\\nâœ… Best Threshold for F1: {best_threshold:.4f}\")\n",
    "\n",
    "# Predict using best threshold\n",
    "y_pred_thresh = (y_proba >= best_threshold).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_thresh))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_thresh))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred_thresh))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_thresh))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_thresh))\n",
    "\n",
    "# Save model, scaler, and threshold\n",
    "model.save_model(\"xgb_churn_model.json\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "joblib.dump(best_threshold, \"best_threshold.pkl\")\n",
    "\n",
    "print(\"\\nâœ… Model, Scaler, and Best Threshold saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: Counter({1.0: 280492, 0.0: 224714})\n",
      "Before SMOTE: Counter({1.0: 224393, 0.0: 179771})\n",
      "After SMOTE: Counter({1.0: 224393, 0.0: 224393})\n",
      "[0]\tvalidation_0-logloss:0.65208\n",
      "[1]\tvalidation_0-logloss:0.61060\n",
      "[2]\tvalidation_0-logloss:0.56942\n",
      "[3]\tvalidation_0-logloss:0.52850\n",
      "[4]\tvalidation_0-logloss:0.49616\n",
      "[5]\tvalidation_0-logloss:0.46881\n",
      "[6]\tvalidation_0-logloss:0.44660\n",
      "[7]\tvalidation_0-logloss:0.42992\n",
      "[8]\tvalidation_0-logloss:0.40944\n",
      "[9]\tvalidation_0-logloss:0.39426\n",
      "[10]\tvalidation_0-logloss:0.38016\n",
      "[11]\tvalidation_0-logloss:0.36657\n",
      "[12]\tvalidation_0-logloss:0.35306\n",
      "[13]\tvalidation_0-logloss:0.34259\n",
      "[14]\tvalidation_0-logloss:0.33371\n",
      "[15]\tvalidation_0-logloss:0.32410\n",
      "[16]\tvalidation_0-logloss:0.31641\n",
      "[17]\tvalidation_0-logloss:0.30979\n",
      "[18]\tvalidation_0-logloss:0.30408\n",
      "[19]\tvalidation_0-logloss:0.29719\n",
      "[20]\tvalidation_0-logloss:0.29274\n",
      "[21]\tvalidation_0-logloss:0.28887\n",
      "[22]\tvalidation_0-logloss:0.28668\n",
      "[23]\tvalidation_0-logloss:0.28391\n",
      "[24]\tvalidation_0-logloss:0.28107\n",
      "[25]\tvalidation_0-logloss:0.27758\n",
      "[26]\tvalidation_0-logloss:0.27483\n",
      "[27]\tvalidation_0-logloss:0.27215\n",
      "[28]\tvalidation_0-logloss:0.26948\n",
      "[29]\tvalidation_0-logloss:0.26643\n",
      "[30]\tvalidation_0-logloss:0.26396\n",
      "[31]\tvalidation_0-logloss:0.26301\n",
      "[32]\tvalidation_0-logloss:0.26048\n",
      "[33]\tvalidation_0-logloss:0.25845\n",
      "[34]\tvalidation_0-logloss:0.25683\n",
      "[35]\tvalidation_0-logloss:0.25576\n",
      "[36]\tvalidation_0-logloss:0.25431\n",
      "[37]\tvalidation_0-logloss:0.25318\n",
      "[38]\tvalidation_0-logloss:0.25234\n",
      "[39]\tvalidation_0-logloss:0.25163\n",
      "[40]\tvalidation_0-logloss:0.25088\n",
      "[41]\tvalidation_0-logloss:0.25000\n",
      "[42]\tvalidation_0-logloss:0.24943\n",
      "[43]\tvalidation_0-logloss:0.24904\n",
      "[44]\tvalidation_0-logloss:0.24848\n",
      "[45]\tvalidation_0-logloss:0.24796\n",
      "[46]\tvalidation_0-logloss:0.24718\n",
      "[47]\tvalidation_0-logloss:0.24651\n",
      "[48]\tvalidation_0-logloss:0.24611\n",
      "[49]\tvalidation_0-logloss:0.24559\n",
      "[50]\tvalidation_0-logloss:0.24532\n",
      "[51]\tvalidation_0-logloss:0.24496\n",
      "[52]\tvalidation_0-logloss:0.24470\n",
      "[53]\tvalidation_0-logloss:0.24444\n",
      "[54]\tvalidation_0-logloss:0.24401\n",
      "[55]\tvalidation_0-logloss:0.24389\n",
      "[56]\tvalidation_0-logloss:0.24345\n",
      "[57]\tvalidation_0-logloss:0.24315\n",
      "[58]\tvalidation_0-logloss:0.24291\n",
      "[59]\tvalidation_0-logloss:0.24247\n",
      "[60]\tvalidation_0-logloss:0.24191\n",
      "[61]\tvalidation_0-logloss:0.24179\n",
      "[62]\tvalidation_0-logloss:0.24166\n",
      "[63]\tvalidation_0-logloss:0.24124\n",
      "[64]\tvalidation_0-logloss:0.24101\n",
      "[65]\tvalidation_0-logloss:0.24096\n",
      "[66]\tvalidation_0-logloss:0.24075\n",
      "[67]\tvalidation_0-logloss:0.24064\n",
      "[68]\tvalidation_0-logloss:0.24031\n",
      "[69]\tvalidation_0-logloss:0.24023\n",
      "[70]\tvalidation_0-logloss:0.24012\n",
      "[71]\tvalidation_0-logloss:0.24001\n",
      "[72]\tvalidation_0-logloss:0.23991\n",
      "[73]\tvalidation_0-logloss:0.23973\n",
      "[74]\tvalidation_0-logloss:0.23947\n",
      "[75]\tvalidation_0-logloss:0.23936\n",
      "[76]\tvalidation_0-logloss:0.23923\n",
      "[77]\tvalidation_0-logloss:0.23918\n",
      "[78]\tvalidation_0-logloss:0.23915\n",
      "[79]\tvalidation_0-logloss:0.23911\n",
      "[80]\tvalidation_0-logloss:0.23896\n",
      "[81]\tvalidation_0-logloss:0.23878\n",
      "[82]\tvalidation_0-logloss:0.23875\n",
      "[83]\tvalidation_0-logloss:0.23871\n",
      "[84]\tvalidation_0-logloss:0.23852\n",
      "[85]\tvalidation_0-logloss:0.23844\n",
      "[86]\tvalidation_0-logloss:0.23839\n",
      "[87]\tvalidation_0-logloss:0.23816\n",
      "[88]\tvalidation_0-logloss:0.23812\n",
      "[89]\tvalidation_0-logloss:0.23808\n",
      "[90]\tvalidation_0-logloss:0.23799\n",
      "[91]\tvalidation_0-logloss:0.23788\n",
      "[92]\tvalidation_0-logloss:0.23781\n",
      "[93]\tvalidation_0-logloss:0.23764\n",
      "[94]\tvalidation_0-logloss:0.23761\n",
      "[95]\tvalidation_0-logloss:0.23740\n",
      "[96]\tvalidation_0-logloss:0.23724\n",
      "[97]\tvalidation_0-logloss:0.23723\n",
      "[98]\tvalidation_0-logloss:0.23719\n",
      "[99]\tvalidation_0-logloss:0.23700\n",
      "\n",
      "Feature Importance:\n",
      "                       Feature  Importance\n",
      "8                  Total Spend    0.269087\n",
      "4                Support Calls    0.239065\n",
      "5                Payment Delay    0.179306\n",
      "7              Contract Length    0.137230\n",
      "0                          Age    0.104014\n",
      "1                       Gender    0.035397\n",
      "2                       Tenure    0.019448\n",
      "3              Usage Frequency    0.009545\n",
      "6            Subscription Type    0.006908\n",
      "9  Days Since Last Interaction    0.000000\n",
      "\n",
      "âœ… Best Threshold for F1: 0.1257\n",
      "\n",
      "Confusion Matrix:\n",
      " [[38319  6624]\n",
      " [  911 55188]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.85      0.91     44943\n",
      "         1.0       0.89      0.98      0.94     56099\n",
      "\n",
      "    accuracy                           0.93    101042\n",
      "   macro avg       0.93      0.92      0.92    101042\n",
      "weighted avg       0.93      0.93      0.92    101042\n",
      "\n",
      "Accuracy Score: 0.9254270501375665\n",
      "Precision: 0.8928363424577752\n",
      "Recall: 0.983760851352074\n",
      "F1 Score: 0.9360958689180822\n",
      "\n",
      "âœ… Model, Scaler, Encoders, and Best Threshold saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, precision_recall_curve, f1_score\n",
    "import joblib\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Load and clean data\n",
    "df = pd.read_csv(\"churn.csv\")\n",
    "df = df.dropna()\n",
    "\n",
    "# Feature engineering\n",
    "df['Last Interaction'] = pd.to_datetime(df['Last Interaction'])\n",
    "df['Days Since Last Interaction'] = (pd.to_datetime(\"today\") - df['Last Interaction']).dt.days\n",
    "df.drop(columns=[\"Last Interaction\", \"CustomerID\"], inplace=True)\n",
    "gender_encoder = LabelEncoder()\n",
    "df[\"Gender\"] = gender_encoder.fit_transform(df[\"Gender\"])\n",
    "\n",
    "subscription_encoder = LabelEncoder()\n",
    "df[\"Subscription Type\"] = subscription_encoder.fit_transform(df[\"Subscription Type\"])\n",
    "\n",
    "contract_encoder = LabelEncoder()\n",
    "df[\"Contract Length\"] = contract_encoder.fit_transform(df[\"Contract Length\"])\n",
    "\n",
    "# Save the encoders for later use\n",
    "joblib.dump(gender_encoder, \"gender_encoder.pkl\")\n",
    "joblib.dump(subscription_encoder, \"subscriptiontype_encoder.pkl\")\n",
    "joblib.dump(contract_encoder, \"contractlength_encoder.pkl\")\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(\"Churn\", axis=1)\n",
    "y = df[\"Churn\"]\n",
    "\n",
    "# Check class distribution\n",
    "print(\"Class distribution:\", Counter(y))\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Handle class imbalance using SMOTE\n",
    "print(\"Before SMOTE:\", Counter(y_train))\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print(\"After SMOTE:\", Counter(y_train_res))\n",
    "\n",
    "# Calculate scale_pos_weight (alternative to SMOTE)\n",
    "# scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "\n",
    "# Train model with optimized parameters\n",
    "# Train model with optimized parameters\n",
    "model = XGBClassifier(\n",
    "    eval_metric='logloss',\n",
    "    scale_pos_weight=0.8,  # Optional alternative to SMOTE\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    early_stopping_rounds=10  # Moved this here from fit()\n",
    ")\n",
    "\n",
    "# Fit with evaluation set\n",
    "model.fit(\n",
    "    X_train_res, y_train_res,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Feature importance\n",
    "print(\"\\nFeature Importance:\")\n",
    "importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "print(importance)\n",
    "\n",
    "# Predict probabilities\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Threshold tuning using F1\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "print(f\"\\nâœ… Best Threshold for F1: {best_threshold:.4f}\")\n",
    "\n",
    "# Predict using best threshold\n",
    "y_pred_thresh = (y_proba >= best_threshold).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_thresh))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_thresh))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred_thresh))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_thresh))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_thresh))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_thresh))\n",
    "\n",
    "# Save model, scaler, encoders, and threshold\n",
    "model.save_model(\"xgb_churn_model.json\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "joblib.dump(best_threshold, \"best_threshold.pkl\")\n",
    "\n",
    "print(\"\\nâœ… Model, Scaler, Encoders, and Best Threshold saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn Probability: 5.94 %\n",
      "Prediction: Not Churn\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load scaler, model, and threshold\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "best_threshold = joblib.load(\"best_threshold.pkl\")\n",
    "\n",
    "# Load label encoders\n",
    "contract_encoder = joblib.load(\"contractlength_encoder.pkl\")\n",
    "gender_encoder = joblib.load(\"gender_encoder.pkl\")\n",
    "subscription_encoder = joblib.load(\"subscriptiontype_encoder.pkl\")\n",
    "\n",
    "# Load XGBoost model\n",
    "model = XGBClassifier()\n",
    "model.load_model(\"xgb_churn_model.json\")\n",
    "\n",
    "# Define feature names in training order\n",
    "columns = [\n",
    "    \"Age\", \"Gender\", \"Tenure\", \"Usage Frequency\", \"Support Calls\",\n",
    "    \"Payment Delay\", \"Subscription Type\", \"Contract Length\",\n",
    "    \"Total Spend\", \"Days Since Last Interaction\"\n",
    "]\n",
    "\n",
    "raw_input = {\n",
    "    \"Age\": 30,\n",
    "    \"Gender\": \"Male\",  # or \"Female\"\n",
    "    \"Tenure\": 24,\n",
    "    \"Usage Frequency\": 5.0,\n",
    "    \"Support Calls\": 0,\n",
    "    \"Payment Delay\": 0.0,\n",
    "    \"Subscription Type\": \"Premium\",  # or \"Basic\", \"Premium\"\n",
    "    \"Contract Length\": \"Annual\",  # or \"Monthly\", \"Quarterly\"\n",
    "    \"Total Spend\": 2400.0,\n",
    "    \"Days Since Last Interaction\": 2\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Encode categorical values using the loaded encoders\n",
    "encoded_input = [\n",
    "    raw_input[\"Age\"],\n",
    "    gender_encoder.transform([raw_input[\"Gender\"]])[0],\n",
    "    raw_input[\"Tenure\"],\n",
    "    raw_input[\"Usage Frequency\"],\n",
    "    raw_input[\"Support Calls\"],\n",
    "    raw_input[\"Payment Delay\"],\n",
    "    subscription_encoder.transform([raw_input[\"Subscription Type\"]])[0],\n",
    "    contract_encoder.transform([raw_input[\"Contract Length\"]])[0],\n",
    "    raw_input[\"Total Spend\"],\n",
    "    raw_input[\"Days Since Last Interaction\"]\n",
    "]\n",
    "\n",
    "# Convert to DataFrame\n",
    "input_df = pd.DataFrame([encoded_input], columns=columns)\n",
    "\n",
    "# Scale input\n",
    "scaled_input = scaler.transform(input_df)\n",
    "\n",
    "# Predict probability of churn\n",
    "proba = model.predict_proba(scaled_input)[:, 1]\n",
    "\n",
    "# Apply custom threshold\n",
    "prediction = (proba >= best_threshold).astype(int)\n",
    "# Output\n",
    "print(\"Churn Probability:\", round(proba[0]*100, 2), \"%\")\n",
    "print(\"Prediction:\", \"Churn\" if prediction[0] == 1 else \"Not Churn\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn Probability: 90.25 %\n",
      "Prediction: Churn\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Load scaler, model, and threshold\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "best_threshold = joblib.load(\"best_threshold.pkl\")\n",
    "\n",
    "# Fix threshold in case it's an array\n",
    "threshold = float(best_threshold) if isinstance(best_threshold, (np.ndarray, list, tuple)) else best_threshold\n",
    "\n",
    "# Load label encoders\n",
    "contract_encoder = joblib.load(\"contractlength_encoder.pkl\")\n",
    "gender_encoder = joblib.load(\"gender_encoder.pkl\")\n",
    "subscription_encoder = joblib.load(\"subscriptiontype_encoder.pkl\")\n",
    "\n",
    "# Load XGBoost model\n",
    "model = XGBClassifier()\n",
    "model.load_model(\"xgb_churn_model.json\")\n",
    "\n",
    "# Define feature names in training order\n",
    "columns = [\n",
    "    \"Age\", \"Gender\", \"Tenure\", \"Usage Frequency\", \"Support Calls\",\n",
    "    \"Payment Delay\", \"Subscription Type\", \"Contract Length\",\n",
    "    \"Total Spend\", \"Days Since Last Interaction\"\n",
    "]\n",
    "\n",
    "# ðŸ” Updated example input (user-style)\n",
    "raw_input = {\n",
    "    \"Age\": 45,\n",
    "    \"Gender\": \"Female\",\n",
    "    \"Tenure\": 2,\n",
    "    \"Usage Frequency\": 3.5,\n",
    "    \"Support Calls\": 4,\n",
    "    \"Payment Delay\": 10.0,\n",
    "    \"Subscription Type\": \"Basic\",\n",
    "    \"Contract Length\": \"Monthly\",\n",
    "    \"Total Spend\": 300.0,\n",
    "    \"Days Since Last Interaction\": 40\n",
    "}\n",
    "\n",
    "# Encode categorical values\n",
    "encoded_input = [\n",
    "    raw_input[\"Age\"],\n",
    "    gender_encoder.transform([raw_input[\"Gender\"]])[0],\n",
    "    raw_input[\"Tenure\"],\n",
    "    raw_input[\"Usage Frequency\"],\n",
    "    raw_input[\"Support Calls\"],\n",
    "    raw_input[\"Payment Delay\"],\n",
    "    subscription_encoder.transform([raw_input[\"Subscription Type\"]])[0],\n",
    "    contract_encoder.transform([raw_input[\"Contract Length\"]])[0],\n",
    "    raw_input[\"Total Spend\"],\n",
    "    raw_input[\"Days Since Last Interaction\"]\n",
    "]\n",
    "\n",
    "# Convert to DataFrame\n",
    "input_df = pd.DataFrame([encoded_input], columns=columns)\n",
    "\n",
    "# Scale input\n",
    "scaled_input = scaler.transform(input_df)\n",
    "\n",
    "# Predict probability of churn\n",
    "proba = model.predict_proba(scaled_input)[:, 1]\n",
    "\n",
    "# Apply custom threshold\n",
    "prediction = (proba >= threshold).astype(int)\n",
    "\n",
    "# Output\n",
    "print(\"Churn Probability:\", round(proba[0] * 100, 2), \"%\")\n",
    "print(\"Prediction:\", \"Churn\" if prediction[0] == 1 else \"Not Churn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn Probability: 5.94 %\n",
      "Prediction: Not Churn\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Load scaler, model, and threshold\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "best_threshold = joblib.load(\"best_threshold.pkl\")\n",
    "\n",
    "# Fix threshold in case it's an array\n",
    "threshold = float(best_threshold) if isinstance(best_threshold, (np.ndarray, list, tuple)) else best_threshold\n",
    "\n",
    "# Load label encoders\n",
    "contract_encoder = joblib.load(\"contractlength_encoder.pkl\")\n",
    "gender_encoder = joblib.load(\"gender_encoder.pkl\")\n",
    "subscription_encoder = joblib.load(\"subscriptiontype_encoder.pkl\")\n",
    "\n",
    "# Load XGBoost model\n",
    "model = XGBClassifier()\n",
    "model.load_model(\"xgb_churn_model.json\")\n",
    "\n",
    "# Define feature names in training order\n",
    "columns = [\n",
    "    \"Age\", \"Gender\", \"Tenure\", \"Usage Frequency\", \"Support Calls\",\n",
    "    \"Payment Delay\", \"Subscription Type\", \"Contract Length\",\n",
    "    \"Total Spend\", \"Days Since Last Interaction\"\n",
    "]\n",
    "\n",
    "# ðŸ” Updated example input (user-style)\n",
    "raw_input = {\n",
    "    \"Age\": 30,\n",
    "    \"Gender\": \"Male\",\n",
    "    \"Tenure\": 24,\n",
    "    \"Usage Frequency\": 5,\n",
    "    \"Support Calls\": 0,\n",
    "    \"Payment Delay\": 0,\n",
    "    \"Subscription Type\": \"Premium\",\n",
    "    \"Contract Length\": \"Annual\",\n",
    "    \"Total Spend\": 2400,\n",
    "    \"Days Since Last Interaction\": 2\n",
    "}\n",
    "\n",
    "# Encode categorical values\n",
    "encoded_input = [\n",
    "    raw_input[\"Age\"],\n",
    "    gender_encoder.transform([raw_input[\"Gender\"]])[0],\n",
    "    raw_input[\"Tenure\"],\n",
    "    raw_input[\"Usage Frequency\"],\n",
    "    raw_input[\"Support Calls\"],\n",
    "    raw_input[\"Payment Delay\"],\n",
    "    subscription_encoder.transform([raw_input[\"Subscription Type\"]])[0],\n",
    "    contract_encoder.transform([raw_input[\"Contract Length\"]])[0],\n",
    "    raw_input[\"Total Spend\"],\n",
    "    raw_input[\"Days Since Last Interaction\"]\n",
    "]\n",
    "\n",
    "# Convert to DataFrame\n",
    "input_df = pd.DataFrame([encoded_input], columns=columns)\n",
    "\n",
    "# Scale input\n",
    "scaled_input = scaler.transform(input_df)\n",
    "\n",
    "# Predict probability of churn\n",
    "proba = model.predict_proba(scaled_input)[:, 1]\n",
    "\n",
    "# Apply custom threshold\n",
    "prediction = (proba >= threshold).astype(int)\n",
    "\n",
    "# Output\n",
    "print(\"Churn Probability:\", round(proba[0] * 100, 2), \"%\")\n",
    "print(\"Prediction:\", \"Churn\" if prediction[0] == 1 else \"Not Churn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
